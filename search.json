[{"path":"https://bips-hb.github.io/arf/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Marvin N. Wright. Author, maintainer. David S. Watson. Author.","code":""},{"path":"https://bips-hb.github.io/arf/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wright M, Watson D (2022). arf: Adversarial random forests. https://github.com/bips-hb/arf, https://bips-hb.github.io/arf/.","code":"@Manual{,   title = {arf: Adversarial random forests},   author = {Marvin N. Wright and David S. Watson},   year = {2022},   note = {https://github.com/bips-hb/arf, https://bips-hb.github.io/arf/}, }"},{"path":"https://bips-hb.github.io/arf/index.html","id":"arf-adversarial-random-forests","dir":"","previous_headings":"","what":"arf: Adversarial Random Forests","title":"Adversarial random forests","text":"Adversarial random forests density estimation generative modeling","code":""},{"path":"https://bips-hb.github.io/arf/index.html","id":"introduction","dir":"","previous_headings":"arf: Adversarial Random Forests","what":"Introduction","title":"Adversarial random forests","text":"Adversarial random forests (ARFs) recursively partition data fully factorized leaves, features jointly independent. procedure iterative, alternating rounds generation discrimination. Data become increasingly realistic round, original synthetic samples can longer reliably distinguished. useful several unsupervised learning tasks, density estimation data synthesis. Methods implemented package. ARFs naturally handle unstructured data mixed continuous categorical covariates. inherit many benefits RFs, including speed, flexibility, solid performance default parameters.","code":""},{"path":"https://bips-hb.github.io/arf/index.html","id":"installation","dir":"","previous_headings":"arf: Adversarial Random Forests","what":"Installation","title":"Adversarial random forests","text":"install development version GitHub using devtools, run","code":"devtools::install_github(\"bips-hb/arf\")"},{"path":[]},{"path":"https://bips-hb.github.io/arf/index.html","id":"density-estimation","dir":"","previous_headings":"arf: Adversarial Random Forests > Examples","what":"Density estimation","title":"Adversarial random forests","text":"run adversarial random forest iris data, perform density estimation calculate log-likelihood data:","code":"arf <- adversarial_rf(iris) psi <- forde(arf, iris) mean(lik(arf, psi, iris))"},{"path":"https://bips-hb.github.io/arf/index.html","id":"generative-modeling","dir":"","previous_headings":"arf: Adversarial Random Forests > Examples","what":"Generative modeling","title":"Adversarial random forests","text":"generate synthetic data based iris data:","code":"arf <- adversarial_rf(iris) psi <- forde(arf, iris) forge(psi, 100)"},{"path":"https://bips-hb.github.io/arf/index.html","id":"references","dir":"","previous_headings":"arf: Adversarial Random Forests","what":"References","title":"Adversarial random forests","text":"Watson, D. S., Blesch, K., Kapar, J. & Wright, M. N. (2022). Adversarial random forests density estimation generative modeling. Preprint: https://arxiv.org/abs/2205.09435.","code":""},{"path":"https://bips-hb.github.io/arf/reference/adversarial_rf.html","id":null,"dir":"Reference","previous_headings":"","what":"Adversarial Random Forests — adversarial_rf","title":"Adversarial Random Forests — adversarial_rf","text":"Implements adversarial random forest learn independence-inducing splits.","code":""},{"path":"https://bips-hb.github.io/arf/reference/adversarial_rf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adversarial Random Forests — adversarial_rf","text":"","code":"adversarial_rf(   x,   num_trees = 10,   min_node_size = 2,   delta = 0,   max_iters = 10,   verbose = TRUE,   parallel = TRUE,   ... )"},{"path":"https://bips-hb.github.io/arf/reference/adversarial_rf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adversarial Random Forests — adversarial_rf","text":"x Input data. Integer variables recoded ordered factors warning. See Details. num_trees Number trees grow forest. default works well generative modeling tasks, increased likelihood estimation. See Details. min_node_size Minimal number real data samples leaf nodes. delta Tolerance parameter. Algorithm converges OOB accuracy < 0.5 + delta. max_iters Maximum iterations adversarial loop. verbose Print discriminator accuracy round? parallel Compute parallel? Must register backend beforehand, e.g. via doParallel. ... Extra parameters passed ranger.","code":""},{"path":"https://bips-hb.github.io/arf/reference/adversarial_rf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adversarial Random Forests — adversarial_rf","text":"random forest object class ranger.","code":""},{"path":"https://bips-hb.github.io/arf/reference/adversarial_rf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adversarial Random Forests — adversarial_rf","text":"adversarial random forest (ARF) algorithm partitions data fully factorized leaves features jointly independent. ARFs trained iteratively, alternating rounds generation discrimination. first instance, synthetic data generated via independent bootstraps feature, RF classifier trained distinguish real synthetic samples. subsequent rounds, synthetic data generated separately leaf, using splits previous forest. creates increasingly realistic data satisfies local independence construction. algorithm converges RF reliably distinguish two classes, .e. OOB accuracy falls 0.5 + delta. ARFs useful several unsupservised learning tasks, density estimation (see forde) data synthesis (see forge). former, recommend increasing number trees improved performance (typically order 100-1000 depending sample size). Integer variables treated ordered factors default. ARF passed forde, estimated distribution variables support observed factor levels (.e., output pmf, pdf). override behavior assign nonzero density intermediate values, explicitly recode features numeric. Note: convergence guaranteed finite samples. max_iter argument sets upper bound number training rounds. Similar results may attained increasing delta. Even single round can often give good performance, data strong complex dependencies may require iterations.","code":""},{"path":"https://bips-hb.github.io/arf/reference/adversarial_rf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adversarial Random Forests — adversarial_rf","text":"Watson, D., Blesch, K., Kapar, J., & Wright, M. (2022). Adversarial random forests density estimation generative modeling. arXiv preprint, 2205.09435.","code":""},{"path":[]},{"path":"https://bips-hb.github.io/arf/reference/adversarial_rf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adversarial Random Forests — adversarial_rf","text":"","code":"arf <- adversarial_rf(iris) #> Iteration: 0, Accuracy: 88.59% #> Warning: executing %dopar% sequentially: no parallel backend registered #> Iteration: 1, Accuracy: 47.49%"},{"path":"https://bips-hb.github.io/arf/reference/forde.html","id":null,"dir":"Reference","previous_headings":"","what":"Forests for Density Estimation — forde","title":"Forests for Density Estimation — forde","text":"Uses pre-trained ARF model estimate leaf distribution parameters.","code":""},{"path":"https://bips-hb.github.io/arf/reference/forde.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forests for Density Estimation — forde","text":"","code":"forde(   arf,   x,   oob = FALSE,   family = \"truncnorm\",   epsilon = 0.1,   parallel = TRUE )"},{"path":"https://bips-hb.github.io/arf/reference/forde.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forests for Density Estimation — forde","text":"arf Pre-trained adversarial_rf. Alternatively, object class ranger. x Training data estimating parameters. oob use --bag samples parameter estimation? TRUE, x must dataset used train arf. family Distribution use density estimation continuous features. Current options include truncated normal (default family = \"truncnorm\") uniform (family = \"unif\"). See Details. epsilon Slack parameter empirical bounds family = \"unif\". avoids zero-density points test data fall outside support training data. gap lower upper bounds expanded factor epsilon. used variable never selected splitting. parallel Compute parallel? Must register backend beforehand, e.g. via doParallel.","code":""},{"path":"https://bips-hb.github.io/arf/reference/forde.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forests for Density Estimation — forde","text":"list 4 elements: (1) parameters continuous data; (2) parameters discrete data; (3) leaf indices coverage; (4) metadata variables. list used estimating likelihoods lik generating data forge.","code":""},{"path":"https://bips-hb.github.io/arf/reference/forde.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Forests for Density Estimation — forde","text":"forde extracts leaf parameters pretrained forest learns distribution parameters data within leaf. former includes coverage (proportion data falling leaf) split criteria. latter includes proportions categorical features mean/variance continuous features. values stored data.table, can used input various functions. Currently, forde provides support limited number distributional families: truncated normal uniform continuous data, multinomial discrete data. Future releases accommodate larger set options. Though forde designed take adversarial random forest input, function's first argument can principle object class ranger. allows users test performance alternative pipelines (e.g., supervised forest input). also requirement x data used fit arf, unless oob = TRUE. fact, using another dataset may protect overfitting. connects Wager & Athey's (2018) notion \"honest trees\".","code":""},{"path":"https://bips-hb.github.io/arf/reference/forde.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forests for Density Estimation — forde","text":"Watson, D., Blesch, K., Kapar, J., & Wright, M. (2022). Adversarial random forests density estimation generative modeling. arXiv preprint, 2205.09435. Wager, S. & Athey, S. (2018). Estimation inference heterogeneous treatment effects using random forests. J. . Stat. Assoc., 113(523): 1228-1242.","code":""},{"path":[]},{"path":"https://bips-hb.github.io/arf/reference/forde.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forests for Density Estimation — forde","text":"","code":"arf <- adversarial_rf(iris) #> Iteration: 0, Accuracy: 87.96% #> Iteration: 1, Accuracy: 47.32% psi <- forde(arf, iris) head(psi) #> $cnt #>          variable       mu      sigma  min  max f_idx #>   1: Sepal.Length 5.091667 0.20890873 -Inf 5.55     8 #>   2: Sepal.Length 4.527273 0.13483997 -Inf  Inf     1 #>   3: Sepal.Length 5.733333 0.05773503 5.55  Inf     9 #>   4: Sepal.Length 6.478571 0.30928844 -Inf  Inf     7 #>   5: Sepal.Length 5.509524 0.30150417 -Inf  Inf    10 #>  ---                                                  #> 524:  Petal.Width 2.266667 0.13165612 -Inf  Inf   119 #> 525:  Petal.Width 1.829412 0.13117119 -Inf  Inf   130 #> 526:  Petal.Width 1.775000 0.26299556 -Inf 2.05   125 #> 527:  Petal.Width 2.350000 0.21213203 -Inf  Inf   120 #> 528:  Petal.Width 1.900000 0.11547005 -Inf  Inf   126 #>  #> $cat #>      variable        val count  prob f_idx #>   1:  Species     setosa    36 1.000     8 #>   2:  Species     setosa    11 1.000     1 #>   3:  Species     setosa     3 1.000     9 #>   4:  Species versicolor    14 1.000     7 #>   5:  Species versicolor    21 1.000    10 #>  ---                                       #> 158:  Species  virginica     4 0.250   124 #> 159:  Species  virginica     4 1.000   125 #> 160:  Species  virginica     2 1.000   120 #> 161:  Species  virginica     4 1.000   126 #> 162:  Species  virginica     8 0.125   118 #>  #> $forest #>      f_idx tree leaf        cvg #>   1:     1    1    8 0.07333333 #>   2:     2    1   22 0.02666667 #>   3:     3    1   24 0.04000000 #>   4:     4    1   26 0.01333333 #>   5:     5    1   27 0.18666667 #>  ---                            #> 128:   128   10   53 0.21333333 #> 129:   129   10   54 0.01333333 #> 130:   130   10   57 0.11333333 #> 131:   131   10   60 0.04666667 #> 132:   132   10   62 0.24000000 #>  #> $meta #>        variable   class    family #> 1: Sepal.Length numeric truncnorm #> 2:  Sepal.Width numeric truncnorm #> 3: Petal.Length numeric truncnorm #> 4:  Petal.Width numeric truncnorm #> 5:      Species  factor  multinom #>"},{"path":"https://bips-hb.github.io/arf/reference/forge.html","id":null,"dir":"Reference","previous_headings":"","what":"Forests for Generative Modeling — forge","title":"Forests for Generative Modeling — forge","text":"Uses pre-trained FORDE model simulate synthetic data.","code":""},{"path":"https://bips-hb.github.io/arf/reference/forge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forests for Generative Modeling — forge","text":"","code":"forge(params, n_synth, parallel = TRUE)"},{"path":"https://bips-hb.github.io/arf/reference/forge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forests for Generative Modeling — forge","text":"params Parameters learned via forde. n_synth Number synthetic samples generate. parallel Compute parallel? Must register backend beforehand, e.g. via doParallel.","code":""},{"path":"https://bips-hb.github.io/arf/reference/forge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forests for Generative Modeling — forge","text":"dataset n_synth synthetic samples.","code":""},{"path":"https://bips-hb.github.io/arf/reference/forge.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Forests for Generative Modeling — forge","text":"forge simulates synthetic dataset n_synth samples. First, leaves sampled proportion coverage. , feature sampled independently within leaf according probability mass density function learned forde. create realistic data long adversarial RF used previous step satisfies local independence criterion. See Watson et al. (2022).","code":""},{"path":"https://bips-hb.github.io/arf/reference/forge.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forests for Generative Modeling — forge","text":"Watson, D., Blesch, K., Kapar, J., & Wright, M. (2022). Adversarial random forests density estimation generative modeling. arXiv preprint, 2205.09435.","code":""},{"path":[]},{"path":"https://bips-hb.github.io/arf/reference/forge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forests for Generative Modeling — forge","text":"","code":"arf <- adversarial_rf(iris) #> Iteration: 0, Accuracy: 80.54% #> Iteration: 1, Accuracy: 42.42% psi <- forde(arf, iris) x_synth <- forge(psi, n_synth = 100)"},{"path":"https://bips-hb.github.io/arf/reference/lik.html","id":null,"dir":"Reference","previous_headings":"","what":"Likelihood Estimation — lik","title":"Likelihood Estimation — lik","text":"Compute density input data.","code":""},{"path":"https://bips-hb.github.io/arf/reference/lik.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Likelihood Estimation — lik","text":"","code":"lik(arf, params, x, oob = FALSE, log = TRUE, batch = NULL, parallel = TRUE)"},{"path":"https://bips-hb.github.io/arf/reference/lik.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Likelihood Estimation — lik","text":"arf Pre-trained adversarial_rf. Alternatively, object class ranger. params Parameters learned via forde. x Input data. Densities computed sample. oob use --bag leaves likelihood estimation? TRUE, x must dataset used train arf. log Return likelihoods log scale? Recommended prevent underflow. batch Batch size. default compute densities x one round, always fastest option memory allows. However, large samples many trees, can memory efficient split data batches. impact results. parallel Compute parallel? Must register backend beforehand, e.g. via doParallel.","code":""},{"path":"https://bips-hb.github.io/arf/reference/lik.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Likelihood Estimation — lik","text":"vector likelihoods, optionally log scale.","code":""},{"path":"https://bips-hb.github.io/arf/reference/lik.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Likelihood Estimation — lik","text":"function computes density input data according FORDE model using pre-trained ARF. sample's likelihood weighted average likelihood leaves whose split criteria satisfies. Intra-leaf densities fully factorized, since ARFs satisfy local independence criterion construction. See Watson et al. (2022).","code":""},{"path":"https://bips-hb.github.io/arf/reference/lik.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Likelihood Estimation — lik","text":"Watson, D., Blesch, K., Kapar, J., & Wright, M. (2022). Adversarial random forests density estimation generative modeling. arXiv preprint, 2205.09435.","code":""},{"path":[]},{"path":"https://bips-hb.github.io/arf/reference/lik.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Likelihood Estimation — lik","text":"","code":"# Estimate average log-likelihood arf <- adversarial_rf(iris) #> Iteration: 0, Accuracy: 88.18% #> Iteration: 1, Accuracy: 45.48% psi <- forde(arf, iris) ll <- lik(arf, psi, iris, log = TRUE) mean(ll) #> [1] -1.260033"}]
